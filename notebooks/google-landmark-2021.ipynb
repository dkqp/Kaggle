{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Google Landmark Recognition 2021\n",
    "\n",
    "https://www.kaggle.com/competitions/landmark-recognition-2021"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import cv2\n",
    "from PIL import Image\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "import torch\n",
    "from torch import nn\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "\n",
    "import torchvision\n",
    "from torchvision import transforms\n",
    "from torchinfo import summary\n",
    "\n",
    "from tqdm.notebook import tqdm_notebook\n",
    "\n",
    "import sys\n",
    "sys.path.append('..')\n",
    "\n",
    "from python_scripts import engine\n",
    "from python_scripts.models import Metrics\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if torch.cuda.is_available():\n",
    "    device = torch.device('cuda')\n",
    "elif torch.backends.mps.is_available():\n",
    "    device = torch.device('mps')\n",
    "else:\n",
    "    device = torch.device('cpu')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "path = '../data/Landmark/'\n",
    "\n",
    "train_data = pd.read_csv(path + 'train.csv')\n",
    "sample_csv = pd.read_csv(path + 'sample_submission.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot 5 (maximum) exmaples of images with the same landmark_id\n",
    "def plot_examples(data=train_data, landmark_id=1):\n",
    "    indexes = data[data['landmark_id'] == landmark_id].index\n",
    "    num_pic = len(indexes) if len(indexes) < 5 else 5\n",
    "    if num_pic == 0:\n",
    "        print('No images available')\n",
    "        return None\n",
    "\n",
    "    fig, axs = plt.subplots(1, num_pic, figsize=(5 * num_pic, 12))\n",
    "    fig.subplots_adjust(hspace=.2, wspace=.2)\n",
    "    axs = axs.ravel()\n",
    "\n",
    "    for i in range(num_pic):\n",
    "        idx = indexes[i]\n",
    "        image_id = train_data.loc[idx]['id']\n",
    "        file = image_id + '.jpg'\n",
    "        subpath = '/'.join([char for char in image_id[0:3]])\n",
    "        img = cv2.imread(path + 'train/' + subpath + '/' + file)\n",
    "        axs[i].imshow(img)\n",
    "        axs[i].set_title('landmark_id: ' + str(landmark_id))\n",
    "        axs[i].set_xticklabels([])\n",
    "        axs[i].set_yticklabels([])\n",
    "\n",
    "plot_examples(train_data, 32349)\n",
    "plot_examples(train_data, 7)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_val_list, _ = train_test_split(list(train_data['id']), train_size=0.01, random_state=42)\n",
    "train_list, val_list = train_test_split(train_val_list, test_size=0.2, random_state=42)\n",
    "test_list = list(sample_csv['id'])\n",
    "\n",
    "len(train_list), len(val_list), len(test_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "img_size = 224\n",
    "batch_size = 64"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_transforms = transforms.Compose([\n",
    "    transforms.RandomRotation(30),\n",
    "    transforms.Resize(img_size),\n",
    "    transforms.RandomHorizontalFlip(),\n",
    "    transforms.ToTensor()\n",
    "])\n",
    "\n",
    "test_transforms = transforms.Compose([\n",
    "    transforms.Resize(img_size),\n",
    "    transforms.ToTensor()\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class DatasetGenerator(Dataset):\n",
    "    def __init__(self, data_list, path, transforms, data=None, image_size=224):\n",
    "        self.data_list = data_list\n",
    "        self.path = path\n",
    "        self.transforms = transforms\n",
    "        self.image_size = image_size\n",
    "        self.data = data\n",
    "        self.classes = []\n",
    "        self.class_to_idx = {}\n",
    "        if self.data is not None and 'landmark_id' in self.data.columns:\n",
    "            self.classes = sorted(self.data['landmark_id'].unique())\n",
    "            self.class_to_idx = dict(zip(self.classes, range(len(self.classes))))\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.data_list)\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        image_id = self.data_list[index]\n",
    "        file = image_id + '.jpg'\n",
    "        subpath = '/'.join([char for char in image_id[0:3]])\n",
    "\n",
    "        image = cv2.imread(self.path + subpath + '/' + file)\n",
    "        image = cv2.resize(image, (self.image_size, self.image_size))\n",
    "        image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB) # used because OpenCV follows BGR convention and PIL follows RGB convention\n",
    "\n",
    "        X = self.transforms(Image.fromarray(image))\n",
    "        y = None\n",
    "        if self.data is not None and 'landmark_id' in self.data.columns:\n",
    "            c = self.data[self.data['id'] == image_id]['landmark_id'].values[0]\n",
    "            y = self.class_to_idx[c]\n",
    "\n",
    "        return X, y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset = DatasetGenerator(\n",
    "    data_list=train_list,\n",
    "    path=path + 'train/',\n",
    "    transforms=train_transforms,\n",
    "    data=train_data,\n",
    "    image_size=img_size\n",
    ")\n",
    "\n",
    "val_dataset = DatasetGenerator(\n",
    "    data_list=val_list,\n",
    "    path=path + 'train/',\n",
    "    transforms=test_transforms,\n",
    "    data=train_data,\n",
    "    image_size=img_size\n",
    ")\n",
    "\n",
    "test_dataset = DatasetGenerator(\n",
    "    data_list=test_list,\n",
    "    path=path + 'test/',\n",
    "    transforms=test_transforms,\n",
    "    image_size=img_size\n",
    ")\n",
    "\n",
    "len(train_dataset), len(val_dataset), len(test_dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class_names = train_dataset.classes\n",
    "class_names[0], len(class_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataloader = DataLoader(\n",
    "    dataset=train_dataset,\n",
    "    batch_size=batch_size,\n",
    "    shuffle=True,\n",
    "    num_workers=1,\n",
    "    pin_memory=True\n",
    ")\n",
    "\n",
    "val_dataloader = DataLoader(\n",
    "    dataset=val_dataset,\n",
    "    batch_size=batch_size,\n",
    "    shuffle=False,\n",
    "    num_workers=1,\n",
    "    pin_memory=True\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "f, ax = plt.subplots(2, 3, figsize=(15, 12))\n",
    "ax = ax.ravel()\n",
    "\n",
    "for i, (data, label) in enumerate(train_dataloader):\n",
    "    img = torchvision.utils.make_grid(data).numpy()\n",
    "    img = np.transpose(img, (1, 2, 0))\n",
    "    img += np.array([1, 1, 1])\n",
    "    img *= 127.5\n",
    "    img = img.astype(np.uint8)\n",
    "    img = img[:, :, [2, 1, 0]]\n",
    "\n",
    "    ax[i].imshow(img)\n",
    "    if i == 6:\n",
    "        break\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "learning_rate_list = [1e-3] # 각 LR 별로 10 epoch 씩 연달아 학습 진행\n",
    "weight_decay_list = [0]\n",
    "epochs_list = [10]\n",
    "batch_size_list = [64]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = torchvision.models.resnet50()\n",
    "model.fc = nn.Linear(\n",
    "    in_features=2048,\n",
    "    out_features=512,\n",
    "    bias=True\n",
    ")\n",
    "summary(model)\n",
    "\n",
    "class Resnet50_Cos(nn.Module):\n",
    "    def __init__(self) -> None:\n",
    "        super().__init__()\n",
    "        weights = torchvision.models.ResNet50_Weights.DEFAULT\n",
    "        self.backbone = torchvision.models.resnet50(weights=weights)\n",
    "        self.backbone.fc = nn.Linear(\n",
    "            in_features=2048,\n",
    "            out_features=512,\n",
    "            bias=True\n",
    "        )\n",
    "        self.metric = Metrics.AddMarginProduct(\n",
    "            in_features=512,\n",
    "            out_features=len(class_names),\n",
    "            m=0.4\n",
    "        )\n",
    "\n",
    "    def forward(self, X, label):\n",
    "        X = self.backbone(X)\n",
    "        output = self.metric(X, label)\n",
    "        return output\n",
    "\n",
    "model = Resnet50_Cos()\n",
    "summary(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tuning_results = engine.HP_tune_train(\n",
    "    model=model,\n",
    "    model_generator=None,\n",
    "    model_weights=None,\n",
    "    model_name='ResNet50_Cos_Google_landmark',\n",
    "    train_dataset=train_dataset,\n",
    "    test_dataset=val_dataset,\n",
    "    learning_rate_list=learning_rate_list,\n",
    "    weight_decay_list=weight_decay_list,\n",
    "    epochs_list=epochs_list,\n",
    "    batch_size_list=batch_size_list,\n",
    "    is_tensorboard_writer=False,\n",
    "    device=device,\n",
    "    gradient_accumulation_num=1,\n",
    "    metric_learning=True\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.eval()\n",
    "train_features = []\n",
    "train_labels = []\n",
    "\n",
    "with torch.inference_mode():\n",
    "    for X_batch_train, y_batch_train in tqdm_notebook(train_dataloader, desc='predict_1', leave=True):\n",
    "        X_batch_train, y_batch_train = X_batch_train.to(device), y_batch_train.to(device)\n",
    "\n",
    "        train_features.append(model.backbone(X_batch_train).detach().cpu())\n",
    "        train_labels.append(y_batch_train.cpu())\n",
    "\n",
    "    train_features = torch.cat(train_features, dim=0)\n",
    "    train_labels = torch.cat(train_labels, dim=0)\n",
    "\n",
    "    for X_test, _ in tqdm_notebook(test_dataset, desc='predict_2', leave=True):\n",
    "        X_test = X_test.to(device)\n",
    "\n",
    "        test_features = model.backbone(X_test.unsqueeze(0)).detach().cpu()\n",
    "        cos_sim = torch.mm(nn.functional.normalize(test_features), nn.functional.normalize(train_features).T)\n",
    "        test_pred = train_labels[torch.argmax(cos_sim, dim=1)]\n",
    "        test_score = torch.max(nn.functional.softmax(cos_sim), dim=1)\n",
    "\n",
    "        category = class_names[test_pred[0].numpy()]\n",
    "        score = test_score[0].numpy()\n",
    "        sample_csv.loc[i]['landmarks'] = str(category) + ' ' + str(score)\n",
    "\n",
    "sample_csv.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sample_csv.to_csv('submission.csv', index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tensorflow",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
