{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Digit Recognizer\n",
    "\n",
    "https://www.kaggle.com/competitions/digit-recognizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 160,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch import nn\n",
    "from torch.utils.data import Dataset\n",
    "import torchvision\n",
    "from torchvision import transforms\n",
    "from torchinfo import summary\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import sys\n",
    "sys.path.append('..')\n",
    "\n",
    "from python_scripts import data_setup, engine\n",
    "from python_scripts.models import ResNet_mnist"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "metadata": {},
   "outputs": [],
   "source": [
    "if torch.cuda.is_available():\n",
    "    device = torch.device('cuda')\n",
    "elif torch.backends.mps.is_available():\n",
    "    device = torch.device('mps')\n",
    "else:\n",
    "    device = torch.device('cpu')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>label</th>\n",
       "      <th>pixel0</th>\n",
       "      <th>pixel1</th>\n",
       "      <th>pixel2</th>\n",
       "      <th>pixel3</th>\n",
       "      <th>pixel4</th>\n",
       "      <th>pixel5</th>\n",
       "      <th>pixel6</th>\n",
       "      <th>pixel7</th>\n",
       "      <th>pixel8</th>\n",
       "      <th>...</th>\n",
       "      <th>pixel774</th>\n",
       "      <th>pixel775</th>\n",
       "      <th>pixel776</th>\n",
       "      <th>pixel777</th>\n",
       "      <th>pixel778</th>\n",
       "      <th>pixel779</th>\n",
       "      <th>pixel780</th>\n",
       "      <th>pixel781</th>\n",
       "      <th>pixel782</th>\n",
       "      <th>pixel783</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>41995</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>41996</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>41997</th>\n",
       "      <td>7</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>41998</th>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>41999</th>\n",
       "      <td>9</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>42000 rows × 785 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       label  pixel0  pixel1  pixel2  pixel3  pixel4  pixel5  pixel6  pixel7  \\\n",
       "0          1       0       0       0       0       0       0       0       0   \n",
       "1          0       0       0       0       0       0       0       0       0   \n",
       "2          1       0       0       0       0       0       0       0       0   \n",
       "3          4       0       0       0       0       0       0       0       0   \n",
       "4          0       0       0       0       0       0       0       0       0   \n",
       "...      ...     ...     ...     ...     ...     ...     ...     ...     ...   \n",
       "41995      0       0       0       0       0       0       0       0       0   \n",
       "41996      1       0       0       0       0       0       0       0       0   \n",
       "41997      7       0       0       0       0       0       0       0       0   \n",
       "41998      6       0       0       0       0       0       0       0       0   \n",
       "41999      9       0       0       0       0       0       0       0       0   \n",
       "\n",
       "       pixel8  ...  pixel774  pixel775  pixel776  pixel777  pixel778  \\\n",
       "0           0  ...         0         0         0         0         0   \n",
       "1           0  ...         0         0         0         0         0   \n",
       "2           0  ...         0         0         0         0         0   \n",
       "3           0  ...         0         0         0         0         0   \n",
       "4           0  ...         0         0         0         0         0   \n",
       "...       ...  ...       ...       ...       ...       ...       ...   \n",
       "41995       0  ...         0         0         0         0         0   \n",
       "41996       0  ...         0         0         0         0         0   \n",
       "41997       0  ...         0         0         0         0         0   \n",
       "41998       0  ...         0         0         0         0         0   \n",
       "41999       0  ...         0         0         0         0         0   \n",
       "\n",
       "       pixel779  pixel780  pixel781  pixel782  pixel783  \n",
       "0             0         0         0         0         0  \n",
       "1             0         0         0         0         0  \n",
       "2             0         0         0         0         0  \n",
       "3             0         0         0         0         0  \n",
       "4             0         0         0         0         0  \n",
       "...         ...       ...       ...       ...       ...  \n",
       "41995         0         0         0         0         0  \n",
       "41996         0         0         0         0         0  \n",
       "41997         0         0         0         0         0  \n",
       "41998         0         0         0         0         0  \n",
       "41999         0         0         0         0         0  \n",
       "\n",
       "[42000 rows x 785 columns]"
      ]
     },
     "execution_count": 147,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train = pd.read_csv('../data/Digit Recognizer/train.csv')\n",
    "train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CustomDataset(Dataset):\n",
    "    def __init__(self, dataframe: pd.DataFrame, transforms: transforms) -> None:\n",
    "        super().__init__()\n",
    "        self.df = dataframe\n",
    "        self.tf = transforms\n",
    "        self.classes = set(self.df['label'].values)\n",
    "    def __getitem__(self, index) -> tuple:\n",
    "        row = np.array(self.df.iloc[index], dtype='uint8')\n",
    "        features = self.tf(row[1:].reshape((28, 28, 1)))\n",
    "        return features, row[0]\n",
    "    def __len__(self) -> int:\n",
    "        return len(self.df)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x29cdf53d0>"
      ]
     },
     "execution_count": 152,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "train_dataset = CustomDataset(\n",
    "    dataframe=train,\n",
    "    transforms=transforms.Compose([\n",
    "      transforms.ToPILImage(),\n",
    "      transforms.RandomRotation(30),\n",
    "      transforms.RandomResizedCrop(28),\n",
    "      transforms.RandomHorizontalFlip(),\n",
    "      transforms.AutoAugment(transforms.AutoAugmentPolicy.IMAGENET),\n",
    "      transforms.ToTensor(),\n",
    "      transforms.Normalize(\n",
    "        [0.485],\n",
    "        [0.229]\n",
    "      )\n",
    "    ])\n",
    ")\n",
    "\n",
    "plt.imshow(train_dataset[0][0].reshape((28, 28, 1)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO] Splitting dataset of length 42000 into splits of size: 29399 and 12601\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{0, 1, 2, 3, 4, 5, 6, 7, 8, 9}"
      ]
     },
     "execution_count": 153,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_sub, val_sub = data_setup.split_dataset(\n",
    "    dataset=train_dataset,\n",
    "    split_size=0.7,\n",
    "    seed=42\n",
    ")\n",
    "\n",
    "class_names = train_dataset.classes\n",
    "class_names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 158,
   "metadata": {},
   "outputs": [],
   "source": [
    "learning_rate_list = [1e-4, 1e-5, 1e-6] # 각 LR 별로 50 epoch 씩 연달아 학습 진행\n",
    "weight_decay_list = [1e-4]\n",
    "epochs_list = [3]\n",
    "batch_size_list = [16]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 161,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "======================================================================\n",
       "Layer (type:depth-idx)                        Param #\n",
       "======================================================================\n",
       "Resnet_mnist                                  --\n",
       "├─Sequential: 1-1                             --\n",
       "│    └─Conv2d: 2-1                            3,136\n",
       "│    └─BatchNorm2d: 2-2                       128\n",
       "│    └─ReLU: 2-3                              --\n",
       "├─Sequential: 1-2                             --\n",
       "│    └─conv_residual_bottleneck: 2-4          --\n",
       "│    │    └─Sequential: 3-1                   58,112\n",
       "│    │    └─Sequential: 3-2                   16,896\n",
       "│    └─conv_residual_bottleneck: 2-5          --\n",
       "│    │    └─Sequential: 3-3                   70,400\n",
       "│    └─conv_residual_bottleneck: 2-6          --\n",
       "│    │    └─Sequential: 3-4                   70,400\n",
       "│    └─conv_residual_bottleneck: 2-7          --\n",
       "│    │    └─Sequential: 3-5                   70,400\n",
       "│    └─conv_residual_bottleneck: 2-8          --\n",
       "│    │    └─Sequential: 3-6                   70,400\n",
       "├─Sequential: 1-3                             --\n",
       "│    └─conv_residual_bottleneck: 2-9          --\n",
       "│    │    └─Sequential: 3-7                   247,296\n",
       "│    │    └─Sequential: 3-8                   132,096\n",
       "│    └─conv_residual_bottleneck: 2-10         --\n",
       "│    │    └─Sequential: 3-9                   280,064\n",
       "│    └─conv_residual_bottleneck: 2-11         --\n",
       "│    │    └─Sequential: 3-10                  280,064\n",
       "│    └─conv_residual_bottleneck: 2-12         --\n",
       "│    │    └─Sequential: 3-11                  280,064\n",
       "│    └─conv_residual_bottleneck: 2-13         --\n",
       "│    │    └─Sequential: 3-12                  280,064\n",
       "│    └─conv_residual_bottleneck: 2-14         --\n",
       "│    │    └─Sequential: 3-13                  280,064\n",
       "│    └─conv_residual_bottleneck: 2-15         --\n",
       "│    │    └─Sequential: 3-14                  280,064\n",
       "│    └─conv_residual_bottleneck: 2-16         --\n",
       "│    │    └─Sequential: 3-15                  280,064\n",
       "│    └─conv_residual_bottleneck: 2-17         --\n",
       "│    │    └─Sequential: 3-16                  280,064\n",
       "│    └─conv_residual_bottleneck: 2-18         --\n",
       "│    │    └─Sequential: 3-17                  280,064\n",
       "│    └─conv_residual_bottleneck: 2-19         --\n",
       "│    │    └─Sequential: 3-18                  280,064\n",
       "│    └─conv_residual_bottleneck: 2-20         --\n",
       "│    │    └─Sequential: 3-19                  280,064\n",
       "│    └─conv_residual_bottleneck: 2-21         --\n",
       "│    │    └─Sequential: 3-20                  280,064\n",
       "│    └─conv_residual_bottleneck: 2-22         --\n",
       "│    │    └─Sequential: 3-21                  280,064\n",
       "│    └─conv_residual_bottleneck: 2-23         --\n",
       "│    │    └─Sequential: 3-22                  280,064\n",
       "│    └─conv_residual_bottleneck: 2-24         --\n",
       "│    │    └─Sequential: 3-23                  280,064\n",
       "│    └─conv_residual_bottleneck: 2-25         --\n",
       "│    │    └─Sequential: 3-24                  280,064\n",
       "│    └─conv_residual_bottleneck: 2-26         --\n",
       "│    │    └─Sequential: 3-25                  280,064\n",
       "│    └─conv_residual_bottleneck: 2-27         --\n",
       "│    │    └─Sequential: 3-26                  280,064\n",
       "│    └─conv_residual_bottleneck: 2-28         --\n",
       "│    │    └─Sequential: 3-27                  280,064\n",
       "│    └─conv_residual_bottleneck: 2-29         --\n",
       "│    │    └─Sequential: 3-28                  280,064\n",
       "│    └─conv_residual_bottleneck: 2-30         --\n",
       "│    │    └─Sequential: 3-29                  280,064\n",
       "│    └─conv_residual_bottleneck: 2-31         --\n",
       "│    │    └─Sequential: 3-30                  280,064\n",
       "│    └─conv_residual_bottleneck: 2-32         --\n",
       "│    │    └─Sequential: 3-31                  280,064\n",
       "│    └─conv_residual_bottleneck: 2-33         --\n",
       "│    │    └─Sequential: 3-32                  280,064\n",
       "├─Sequential: 1-4                             --\n",
       "│    └─conv_residual_bottleneck: 2-34         --\n",
       "│    │    └─Sequential: 3-33                  986,112\n",
       "│    │    └─Sequential: 3-34                  526,336\n",
       "│    └─conv_residual_bottleneck: 2-35         --\n",
       "│    │    └─Sequential: 3-35                  1,117,184\n",
       "│    └─conv_residual_bottleneck: 2-36         --\n",
       "│    │    └─Sequential: 3-36                  1,117,184\n",
       "│    └─conv_residual_bottleneck: 2-37         --\n",
       "│    │    └─Sequential: 3-37                  1,117,184\n",
       "│    └─conv_residual_bottleneck: 2-38         --\n",
       "│    │    └─Sequential: 3-38                  1,117,184\n",
       "├─Sequential: 1-5                             --\n",
       "│    └─AdaptiveAvgPool2d: 2-39                --\n",
       "│    └─Flatten: 2-40                          --\n",
       "│    └─Linear: 2-41                           10,250\n",
       "======================================================================\n",
       "Total params: 13,452,234\n",
       "Trainable params: 13,452,234\n",
       "Non-trainable params: 0\n",
       "======================================================================"
      ]
     },
     "execution_count": 161,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = ResNet_mnist.Resnet_mnist(\n",
    "    in_channels=1,\n",
    "    num_classes=len(class_names)\n",
    ")\n",
    "\n",
    "summary(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 162,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8cef9db9d8a040ffb477267ebbd25ca7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/3 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 0 | Train_loss: 1.5259, Train_acc: 0.4876 | Test_loss: 1.2990, Test_acc: 0.5875\n",
      "Epoch: 1 | Train_loss: 1.0859, Train_acc: 0.6443 | Test_loss: 1.0140, Test_acc: 0.6692\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m/Users/tglim/Kaggle/notebooks/digit-recognizer.ipynb Cell 10\u001b[0m in \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> <a href='vscode-notebook-cell:/Users/tglim/Kaggle/notebooks/digit-recognizer.ipynb#X16sZmlsZQ%3D%3D?line=0'>1</a>\u001b[0m tuning_results \u001b[39m=\u001b[39m engine\u001b[39m.\u001b[39;49mHP_tune_train(\n\u001b[1;32m      <a href='vscode-notebook-cell:/Users/tglim/Kaggle/notebooks/digit-recognizer.ipynb#X16sZmlsZQ%3D%3D?line=1'>2</a>\u001b[0m     model\u001b[39m=\u001b[39;49mmodel,\n\u001b[1;32m      <a href='vscode-notebook-cell:/Users/tglim/Kaggle/notebooks/digit-recognizer.ipynb#X16sZmlsZQ%3D%3D?line=2'>3</a>\u001b[0m     model_generator\u001b[39m=\u001b[39;49m\u001b[39mNone\u001b[39;49;00m,\n\u001b[1;32m      <a href='vscode-notebook-cell:/Users/tglim/Kaggle/notebooks/digit-recognizer.ipynb#X16sZmlsZQ%3D%3D?line=3'>4</a>\u001b[0m     model_weights\u001b[39m=\u001b[39;49m\u001b[39mNone\u001b[39;49;00m,\n\u001b[1;32m      <a href='vscode-notebook-cell:/Users/tglim/Kaggle/notebooks/digit-recognizer.ipynb#X16sZmlsZQ%3D%3D?line=4'>5</a>\u001b[0m     model_name\u001b[39m=\u001b[39;49m\u001b[39m'\u001b[39;49m\u001b[39mResNet_mnist\u001b[39;49m\u001b[39m'\u001b[39;49m,\n\u001b[1;32m      <a href='vscode-notebook-cell:/Users/tglim/Kaggle/notebooks/digit-recognizer.ipynb#X16sZmlsZQ%3D%3D?line=5'>6</a>\u001b[0m     train_dataset\u001b[39m=\u001b[39;49mtrain_sub,\n\u001b[1;32m      <a href='vscode-notebook-cell:/Users/tglim/Kaggle/notebooks/digit-recognizer.ipynb#X16sZmlsZQ%3D%3D?line=6'>7</a>\u001b[0m     test_dataset\u001b[39m=\u001b[39;49mval_sub,\n\u001b[1;32m      <a href='vscode-notebook-cell:/Users/tglim/Kaggle/notebooks/digit-recognizer.ipynb#X16sZmlsZQ%3D%3D?line=7'>8</a>\u001b[0m     learning_rate_list\u001b[39m=\u001b[39;49mlearning_rate_list,\n\u001b[1;32m      <a href='vscode-notebook-cell:/Users/tglim/Kaggle/notebooks/digit-recognizer.ipynb#X16sZmlsZQ%3D%3D?line=8'>9</a>\u001b[0m     weight_decay_list\u001b[39m=\u001b[39;49mweight_decay_list,\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/tglim/Kaggle/notebooks/digit-recognizer.ipynb#X16sZmlsZQ%3D%3D?line=9'>10</a>\u001b[0m     epochs_list\u001b[39m=\u001b[39;49mepochs_list,\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/tglim/Kaggle/notebooks/digit-recognizer.ipynb#X16sZmlsZQ%3D%3D?line=10'>11</a>\u001b[0m     batch_size_list\u001b[39m=\u001b[39;49mbatch_size_list,\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/tglim/Kaggle/notebooks/digit-recognizer.ipynb#X16sZmlsZQ%3D%3D?line=11'>12</a>\u001b[0m     is_tensorboard_writer\u001b[39m=\u001b[39;49m\u001b[39mFalse\u001b[39;49;00m,\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/tglim/Kaggle/notebooks/digit-recognizer.ipynb#X16sZmlsZQ%3D%3D?line=12'>13</a>\u001b[0m     device\u001b[39m=\u001b[39;49mdevice,\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/tglim/Kaggle/notebooks/digit-recognizer.ipynb#X16sZmlsZQ%3D%3D?line=13'>14</a>\u001b[0m     gradient_accumulation_num\u001b[39m=\u001b[39;49m\u001b[39m1\u001b[39;49m\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/tglim/Kaggle/notebooks/digit-recognizer.ipynb#X16sZmlsZQ%3D%3D?line=14'>15</a>\u001b[0m )\n",
      "File \u001b[0;32m~/Kaggle/notebooks/../python_scripts/engine.py:189\u001b[0m, in \u001b[0;36mHP_tune_train\u001b[0;34m(model, model_generator, model_weights, model_name, train_dataset, test_dataset, learning_rate_list, weight_decay_list, epochs_list, batch_size_list, is_tensorboard_writer, device, gradient_accumulation_num)\u001b[0m\n\u001b[1;32m    183\u001b[0m \u001b[39mif\u001b[39;00m is_tensorboard_writer:\n\u001b[1;32m    184\u001b[0m     writer \u001b[39m=\u001b[39m utils\u001b[39m.\u001b[39mcreate_writer(\n\u001b[1;32m    185\u001b[0m         experiment_name\u001b[39m=\u001b[39m model_name \u001b[39m+\u001b[39m \u001b[39m'\u001b[39m\u001b[39m_test\u001b[39m\u001b[39m'\u001b[39m,\n\u001b[1;32m    186\u001b[0m         model_name\u001b[39m=\u001b[39mmodel_name,\n\u001b[1;32m    187\u001b[0m         extra\u001b[39m=\u001b[39m\u001b[39mf\u001b[39m\u001b[39m'\u001b[39m\u001b[39mLR_\u001b[39m\u001b[39m{\u001b[39;00mlearning_rate\u001b[39m}\u001b[39;00m\u001b[39m_WD_\u001b[39m\u001b[39m{\u001b[39;00mweight_decay\u001b[39m}\u001b[39;00m\u001b[39m_EP_\u001b[39m\u001b[39m{\u001b[39;00mepochs\u001b[39m}\u001b[39;00m\u001b[39m_BS_\u001b[39m\u001b[39m{\u001b[39;00mbatch_size\u001b[39m}\u001b[39;00m\u001b[39m_GA_\u001b[39m\u001b[39m{\u001b[39;00mgradient_accumulation_num\u001b[39m}\u001b[39;00m\u001b[39m'\u001b[39m\n\u001b[1;32m    188\u001b[0m     )\n\u001b[0;32m--> 189\u001b[0m model_results \u001b[39m=\u001b[39m train_tensorboard_gradient_accumulation(\n\u001b[1;32m    190\u001b[0m     model\u001b[39m=\u001b[39;49mmodel,\n\u001b[1;32m    191\u001b[0m     train_dataloader\u001b[39m=\u001b[39;49mtrain_dataloader,\n\u001b[1;32m    192\u001b[0m     test_dataloader\u001b[39m=\u001b[39;49mtest_dataloader,\n\u001b[1;32m    193\u001b[0m     loss_fn\u001b[39m=\u001b[39;49mnn\u001b[39m.\u001b[39;49mCrossEntropyLoss(),\n\u001b[1;32m    194\u001b[0m     optimizer\u001b[39m=\u001b[39;49mtorch\u001b[39m.\u001b[39;49moptim\u001b[39m.\u001b[39;49mAdam(\n\u001b[1;32m    195\u001b[0m         params\u001b[39m=\u001b[39;49mmodel\u001b[39m.\u001b[39;49mparameters(),\n\u001b[1;32m    196\u001b[0m         lr\u001b[39m=\u001b[39;49mlearning_rate,\n\u001b[1;32m    197\u001b[0m         weight_decay\u001b[39m=\u001b[39;49mweight_decay\n\u001b[1;32m    198\u001b[0m     ),\n\u001b[1;32m    199\u001b[0m     accuracy_fn\u001b[39m=\u001b[39;49mAccuracy(\n\u001b[1;32m    200\u001b[0m         task\u001b[39m=\u001b[39;49m\u001b[39m'\u001b[39;49m\u001b[39mmulticlass\u001b[39;49m\u001b[39m'\u001b[39;49m,\n\u001b[1;32m    201\u001b[0m         num_classes\u001b[39m=\u001b[39;49m\u001b[39mlen\u001b[39;49m(class_names_food101)\n\u001b[1;32m    202\u001b[0m     ),\n\u001b[1;32m    203\u001b[0m     epochs\u001b[39m=\u001b[39;49mepochs,\n\u001b[1;32m    204\u001b[0m     device\u001b[39m=\u001b[39;49mdevice,\n\u001b[1;32m    205\u001b[0m     writer\u001b[39m=\u001b[39;49mwriter,\n\u001b[1;32m    206\u001b[0m     accumulation_num\u001b[39m=\u001b[39;49mgradient_accumulation_num\n\u001b[1;32m    207\u001b[0m )\n\u001b[1;32m    209\u001b[0m t_result[\u001b[39m'\u001b[39m\u001b[39mtrain_loss\u001b[39m\u001b[39m'\u001b[39m] \u001b[39m=\u001b[39m model_results[\u001b[39m'\u001b[39m\u001b[39mtrain_loss\u001b[39m\u001b[39m'\u001b[39m][\u001b[39m-\u001b[39m\u001b[39m1\u001b[39m]\n\u001b[1;32m    210\u001b[0m t_result[\u001b[39m'\u001b[39m\u001b[39mtest_loss\u001b[39m\u001b[39m'\u001b[39m] \u001b[39m=\u001b[39m model_results[\u001b[39m'\u001b[39m\u001b[39mtest_loss\u001b[39m\u001b[39m'\u001b[39m][\u001b[39m-\u001b[39m\u001b[39m1\u001b[39m]\n",
      "File \u001b[0;32m~/Kaggle/notebooks/../python_scripts/engine.py:104\u001b[0m, in \u001b[0;36mtrain_tensorboard_gradient_accumulation\u001b[0;34m(model, train_dataloader, test_dataloader, loss_fn, optimizer, accuracy_fn, epochs, device, writer, accumulation_num)\u001b[0m\n\u001b[1;32m    101\u001b[0m model\u001b[39m.\u001b[39mto(device)\n\u001b[1;32m    103\u001b[0m \u001b[39mfor\u001b[39;00m epoch \u001b[39min\u001b[39;00m tqdm(\u001b[39mrange\u001b[39m(epochs)):\n\u001b[0;32m--> 104\u001b[0m     train_loss, train_acc \u001b[39m=\u001b[39m train_step_gradient_accumulation(model\u001b[39m=\u001b[39;49mmodel,\n\u001b[1;32m    105\u001b[0m                                        dataloader\u001b[39m=\u001b[39;49mtrain_dataloader,\n\u001b[1;32m    106\u001b[0m                                        loss_fn\u001b[39m=\u001b[39;49mloss_fn,\n\u001b[1;32m    107\u001b[0m                                        optimizer\u001b[39m=\u001b[39;49moptimizer,\n\u001b[1;32m    108\u001b[0m                                        accuracy_fn\u001b[39m=\u001b[39;49maccuracy_fn,\n\u001b[1;32m    109\u001b[0m                                        device\u001b[39m=\u001b[39;49mdevice,\n\u001b[1;32m    110\u001b[0m                                        accumulation_num\u001b[39m=\u001b[39;49maccumulation_num)\n\u001b[1;32m    111\u001b[0m     test_loss, test_acc \u001b[39m=\u001b[39m test_step(model\u001b[39m=\u001b[39mmodel,\n\u001b[1;32m    112\u001b[0m                                     dataloader\u001b[39m=\u001b[39mtest_dataloader,\n\u001b[1;32m    113\u001b[0m                                     loss_fn\u001b[39m=\u001b[39mloss_fn,\n\u001b[1;32m    114\u001b[0m                                     accuracy_fn\u001b[39m=\u001b[39maccuracy_fn,\n\u001b[1;32m    115\u001b[0m                                     device\u001b[39m=\u001b[39mdevice)\n\u001b[1;32m    117\u001b[0m     results[\u001b[39m'\u001b[39m\u001b[39mtrain_loss\u001b[39m\u001b[39m'\u001b[39m]\u001b[39m.\u001b[39mappend(train_loss\u001b[39m.\u001b[39mdetach()\u001b[39m.\u001b[39mcpu()\u001b[39m.\u001b[39mnumpy())\n",
      "File \u001b[0;32m~/Kaggle/notebooks/../python_scripts/engine.py:50\u001b[0m, in \u001b[0;36mtrain_step_gradient_accumulation\u001b[0;34m(model, dataloader, loss_fn, optimizer, accuracy_fn, device, accumulation_num)\u001b[0m\n\u001b[1;32m     47\u001b[0m loss\u001b[39m.\u001b[39mbackward()\n\u001b[1;32m     49\u001b[0m \u001b[39mif\u001b[39;00m (iter_total \u001b[39m+\u001b[39m \u001b[39m1\u001b[39m) \u001b[39m%\u001b[39m accumulation_num \u001b[39m==\u001b[39m \u001b[39m0\u001b[39m:\n\u001b[0;32m---> 50\u001b[0m   optimizer\u001b[39m.\u001b[39;49mstep()\n\u001b[1;32m     51\u001b[0m   optimizer\u001b[39m.\u001b[39mzero_grad()\n\u001b[1;32m     53\u001b[0m iter_total \u001b[39m+\u001b[39m\u001b[39m=\u001b[39m \u001b[39m1\u001b[39m\n",
      "File \u001b[0;32m~/miniforge3/envs/tensorflow/lib/python3.8/site-packages/torch/optim/optimizer.py:140\u001b[0m, in \u001b[0;36mOptimizer._hook_for_profile.<locals>.profile_hook_step.<locals>.wrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    138\u001b[0m profile_name \u001b[39m=\u001b[39m \u001b[39m\"\u001b[39m\u001b[39mOptimizer.step#\u001b[39m\u001b[39m{}\u001b[39;00m\u001b[39m.step\u001b[39m\u001b[39m\"\u001b[39m\u001b[39m.\u001b[39mformat(obj\u001b[39m.\u001b[39m\u001b[39m__class__\u001b[39m\u001b[39m.\u001b[39m\u001b[39m__name__\u001b[39m)\n\u001b[1;32m    139\u001b[0m \u001b[39mwith\u001b[39;00m torch\u001b[39m.\u001b[39mautograd\u001b[39m.\u001b[39mprofiler\u001b[39m.\u001b[39mrecord_function(profile_name):\n\u001b[0;32m--> 140\u001b[0m     out \u001b[39m=\u001b[39m func(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m    141\u001b[0m     obj\u001b[39m.\u001b[39m_optimizer_step_code()\n\u001b[1;32m    142\u001b[0m     \u001b[39mreturn\u001b[39;00m out\n",
      "File \u001b[0;32m~/miniforge3/envs/tensorflow/lib/python3.8/site-packages/torch/optim/optimizer.py:23\u001b[0m, in \u001b[0;36m_use_grad_for_differentiable.<locals>._use_grad\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m     21\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m     22\u001b[0m     torch\u001b[39m.\u001b[39mset_grad_enabled(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mdefaults[\u001b[39m'\u001b[39m\u001b[39mdifferentiable\u001b[39m\u001b[39m'\u001b[39m])\n\u001b[0;32m---> 23\u001b[0m     ret \u001b[39m=\u001b[39m func(\u001b[39mself\u001b[39;49m, \u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m     24\u001b[0m \u001b[39mfinally\u001b[39;00m:\n\u001b[1;32m     25\u001b[0m     torch\u001b[39m.\u001b[39mset_grad_enabled(prev_grad)\n",
      "File \u001b[0;32m~/miniforge3/envs/tensorflow/lib/python3.8/site-packages/torch/optim/adam.py:234\u001b[0m, in \u001b[0;36mAdam.step\u001b[0;34m(self, closure, grad_scaler)\u001b[0m\n\u001b[1;32m    231\u001b[0m                 \u001b[39mraise\u001b[39;00m \u001b[39mRuntimeError\u001b[39;00m(\u001b[39m'\u001b[39m\u001b[39m`requires_grad` is not supported for `step` in differentiable mode\u001b[39m\u001b[39m'\u001b[39m)\n\u001b[1;32m    232\u001b[0m             state_steps\u001b[39m.\u001b[39mappend(state[\u001b[39m'\u001b[39m\u001b[39mstep\u001b[39m\u001b[39m'\u001b[39m])\n\u001b[0;32m--> 234\u001b[0m     adam(params_with_grad,\n\u001b[1;32m    235\u001b[0m          grads,\n\u001b[1;32m    236\u001b[0m          exp_avgs,\n\u001b[1;32m    237\u001b[0m          exp_avg_sqs,\n\u001b[1;32m    238\u001b[0m          max_exp_avg_sqs,\n\u001b[1;32m    239\u001b[0m          state_steps,\n\u001b[1;32m    240\u001b[0m          amsgrad\u001b[39m=\u001b[39;49mgroup[\u001b[39m'\u001b[39;49m\u001b[39mamsgrad\u001b[39;49m\u001b[39m'\u001b[39;49m],\n\u001b[1;32m    241\u001b[0m          beta1\u001b[39m=\u001b[39;49mbeta1,\n\u001b[1;32m    242\u001b[0m          beta2\u001b[39m=\u001b[39;49mbeta2,\n\u001b[1;32m    243\u001b[0m          lr\u001b[39m=\u001b[39;49mgroup[\u001b[39m'\u001b[39;49m\u001b[39mlr\u001b[39;49m\u001b[39m'\u001b[39;49m],\n\u001b[1;32m    244\u001b[0m          weight_decay\u001b[39m=\u001b[39;49mgroup[\u001b[39m'\u001b[39;49m\u001b[39mweight_decay\u001b[39;49m\u001b[39m'\u001b[39;49m],\n\u001b[1;32m    245\u001b[0m          eps\u001b[39m=\u001b[39;49mgroup[\u001b[39m'\u001b[39;49m\u001b[39meps\u001b[39;49m\u001b[39m'\u001b[39;49m],\n\u001b[1;32m    246\u001b[0m          maximize\u001b[39m=\u001b[39;49mgroup[\u001b[39m'\u001b[39;49m\u001b[39mmaximize\u001b[39;49m\u001b[39m'\u001b[39;49m],\n\u001b[1;32m    247\u001b[0m          foreach\u001b[39m=\u001b[39;49mgroup[\u001b[39m'\u001b[39;49m\u001b[39mforeach\u001b[39;49m\u001b[39m'\u001b[39;49m],\n\u001b[1;32m    248\u001b[0m          capturable\u001b[39m=\u001b[39;49mgroup[\u001b[39m'\u001b[39;49m\u001b[39mcapturable\u001b[39;49m\u001b[39m'\u001b[39;49m],\n\u001b[1;32m    249\u001b[0m          differentiable\u001b[39m=\u001b[39;49mgroup[\u001b[39m'\u001b[39;49m\u001b[39mdifferentiable\u001b[39;49m\u001b[39m'\u001b[39;49m],\n\u001b[1;32m    250\u001b[0m          fused\u001b[39m=\u001b[39;49mgroup[\u001b[39m'\u001b[39;49m\u001b[39mfused\u001b[39;49m\u001b[39m'\u001b[39;49m],\n\u001b[1;32m    251\u001b[0m          grad_scale\u001b[39m=\u001b[39;49mgrad_scale,\n\u001b[1;32m    252\u001b[0m          found_inf\u001b[39m=\u001b[39;49mfound_inf)\n\u001b[1;32m    254\u001b[0m \u001b[39mreturn\u001b[39;00m loss\n",
      "File \u001b[0;32m~/miniforge3/envs/tensorflow/lib/python3.8/site-packages/torch/optim/adam.py:300\u001b[0m, in \u001b[0;36madam\u001b[0;34m(params, grads, exp_avgs, exp_avg_sqs, max_exp_avg_sqs, state_steps, foreach, capturable, differentiable, fused, grad_scale, found_inf, amsgrad, beta1, beta2, lr, weight_decay, eps, maximize)\u001b[0m\n\u001b[1;32m    297\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[1;32m    298\u001b[0m     func \u001b[39m=\u001b[39m _single_tensor_adam\n\u001b[0;32m--> 300\u001b[0m func(params,\n\u001b[1;32m    301\u001b[0m      grads,\n\u001b[1;32m    302\u001b[0m      exp_avgs,\n\u001b[1;32m    303\u001b[0m      exp_avg_sqs,\n\u001b[1;32m    304\u001b[0m      max_exp_avg_sqs,\n\u001b[1;32m    305\u001b[0m      state_steps,\n\u001b[1;32m    306\u001b[0m      amsgrad\u001b[39m=\u001b[39;49mamsgrad,\n\u001b[1;32m    307\u001b[0m      beta1\u001b[39m=\u001b[39;49mbeta1,\n\u001b[1;32m    308\u001b[0m      beta2\u001b[39m=\u001b[39;49mbeta2,\n\u001b[1;32m    309\u001b[0m      lr\u001b[39m=\u001b[39;49mlr,\n\u001b[1;32m    310\u001b[0m      weight_decay\u001b[39m=\u001b[39;49mweight_decay,\n\u001b[1;32m    311\u001b[0m      eps\u001b[39m=\u001b[39;49meps,\n\u001b[1;32m    312\u001b[0m      maximize\u001b[39m=\u001b[39;49mmaximize,\n\u001b[1;32m    313\u001b[0m      capturable\u001b[39m=\u001b[39;49mcapturable,\n\u001b[1;32m    314\u001b[0m      differentiable\u001b[39m=\u001b[39;49mdifferentiable,\n\u001b[1;32m    315\u001b[0m      grad_scale\u001b[39m=\u001b[39;49mgrad_scale,\n\u001b[1;32m    316\u001b[0m      found_inf\u001b[39m=\u001b[39;49mfound_inf)\n",
      "File \u001b[0;32m~/miniforge3/envs/tensorflow/lib/python3.8/site-packages/torch/optim/adam.py:410\u001b[0m, in \u001b[0;36m_single_tensor_adam\u001b[0;34m(params, grads, exp_avgs, exp_avg_sqs, max_exp_avg_sqs, state_steps, grad_scale, found_inf, amsgrad, beta1, beta2, lr, weight_decay, eps, maximize, capturable, differentiable)\u001b[0m\n\u001b[1;32m    408\u001b[0m     denom \u001b[39m=\u001b[39m (max_exp_avg_sqs[i]\u001b[39m.\u001b[39msqrt() \u001b[39m/\u001b[39m bias_correction2_sqrt)\u001b[39m.\u001b[39madd_(eps)\n\u001b[1;32m    409\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[0;32m--> 410\u001b[0m     denom \u001b[39m=\u001b[39m (exp_avg_sq\u001b[39m.\u001b[39;49msqrt() \u001b[39m/\u001b[39m bias_correction2_sqrt)\u001b[39m.\u001b[39madd_(eps)\n\u001b[1;32m    412\u001b[0m param\u001b[39m.\u001b[39maddcdiv_(exp_avg, denom, value\u001b[39m=\u001b[39m\u001b[39m-\u001b[39mstep_size)\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "tuning_results = engine.HP_tune_train(\n",
    "    model=model,\n",
    "    model_generator=None,\n",
    "    model_weights=None,\n",
    "    model_name='ResNet_mnist',\n",
    "    train_dataset=train_sub,\n",
    "    test_dataset=val_sub,\n",
    "    learning_rate_list=learning_rate_list,\n",
    "    weight_decay_list=weight_decay_list,\n",
    "    epochs_list=epochs_list,\n",
    "    batch_size_list=batch_size_list,\n",
    "    is_tensorboard_writer=False,\n",
    "    device=device,\n",
    "    gradient_accumulation_num=1\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tensorflow",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "9eeb77476765327a5766bde23db868cdced0c0ccde5f7598d5cda0f5c8e639e5"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
