{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# RNA Reactivity Training\n",
    "https://www.kaggle.com/competitions/stanford-ribonanza-rna-folding/overview"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "TRAIN_DATA_PATH = '../data/small_sets/train_data_QUICK_START.csv'\n",
    "TRAIN_DATA_EXT_PATH = '../data/small_sets/train_extracted.csv'\n",
    "VOCAB_PATH = '../data/vocab.csv'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sequence_id</th>\n",
       "      <th>sequence</th>\n",
       "      <th>experiment_type</th>\n",
       "      <th>dataset_name</th>\n",
       "      <th>reactivity_0001</th>\n",
       "      <th>reactivity_0002</th>\n",
       "      <th>reactivity_0003</th>\n",
       "      <th>reactivity_0004</th>\n",
       "      <th>reactivity_0005</th>\n",
       "      <th>reactivity_0006</th>\n",
       "      <th>...</th>\n",
       "      <th>reactivity_error_0197</th>\n",
       "      <th>reactivity_error_0198</th>\n",
       "      <th>reactivity_error_0199</th>\n",
       "      <th>reactivity_error_0200</th>\n",
       "      <th>reactivity_error_0201</th>\n",
       "      <th>reactivity_error_0202</th>\n",
       "      <th>reactivity_error_0203</th>\n",
       "      <th>reactivity_error_0204</th>\n",
       "      <th>reactivity_error_0205</th>\n",
       "      <th>reactivity_error_0206</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0000d87cab97</td>\n",
       "      <td>GGGAACGACUCGAGUAGAGUCGAAAAAGAUCGCCACGCACUUACGA...</td>\n",
       "      <td>2A3_MaP</td>\n",
       "      <td>DasLabBigLib_OneMil_RFAM_windows_100mers_2A3</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0000d87cab97</td>\n",
       "      <td>GGGAACGACUCGAGUAGAGUCGAAAAAGAUCGCCACGCACUUACGA...</td>\n",
       "      <td>DMS_MaP</td>\n",
       "      <td>DasLabBigLib_OneMil_RFAM_windows_100mers_DMS</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0001ca9d21b0</td>\n",
       "      <td>GGGAACGACUCGAGUAGAGUCGAAAAGGUGGCCGGCAGAAUCGCGA...</td>\n",
       "      <td>2A3_MaP</td>\n",
       "      <td>DasLabBigLib_OneMil_OpenKnot_Round_2_train_2A3</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0001ca9d21b0</td>\n",
       "      <td>GGGAACGACUCGAGUAGAGUCGAAAAGGUGGCCGGCAGAAUCGCGA...</td>\n",
       "      <td>DMS_MaP</td>\n",
       "      <td>DasLabBigLib_OneMil_OpenKnot_Round_2_train_DMS</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>00021f968267</td>\n",
       "      <td>GGGAACGACUCGAGUAGAGUCGAAAACAUUGUUAAUGCCUAUAUUA...</td>\n",
       "      <td>2A3_MaP</td>\n",
       "      <td>DasLabBigLib_OneMil_Replicates_from_previous_l...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 416 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "    sequence_id                                           sequence  \\\n",
       "0  0000d87cab97  GGGAACGACUCGAGUAGAGUCGAAAAAGAUCGCCACGCACUUACGA...   \n",
       "1  0000d87cab97  GGGAACGACUCGAGUAGAGUCGAAAAAGAUCGCCACGCACUUACGA...   \n",
       "2  0001ca9d21b0  GGGAACGACUCGAGUAGAGUCGAAAAGGUGGCCGGCAGAAUCGCGA...   \n",
       "3  0001ca9d21b0  GGGAACGACUCGAGUAGAGUCGAAAAGGUGGCCGGCAGAAUCGCGA...   \n",
       "4  00021f968267  GGGAACGACUCGAGUAGAGUCGAAAACAUUGUUAAUGCCUAUAUUA...   \n",
       "\n",
       "  experiment_type                                       dataset_name  \\\n",
       "0         2A3_MaP       DasLabBigLib_OneMil_RFAM_windows_100mers_2A3   \n",
       "1         DMS_MaP       DasLabBigLib_OneMil_RFAM_windows_100mers_DMS   \n",
       "2         2A3_MaP     DasLabBigLib_OneMil_OpenKnot_Round_2_train_2A3   \n",
       "3         DMS_MaP     DasLabBigLib_OneMil_OpenKnot_Round_2_train_DMS   \n",
       "4         2A3_MaP  DasLabBigLib_OneMil_Replicates_from_previous_l...   \n",
       "\n",
       "   reactivity_0001  reactivity_0002  reactivity_0003  reactivity_0004  \\\n",
       "0              NaN              NaN              NaN              NaN   \n",
       "1              NaN              NaN              NaN              NaN   \n",
       "2              NaN              NaN              NaN              NaN   \n",
       "3              NaN              NaN              NaN              NaN   \n",
       "4              NaN              NaN              NaN              NaN   \n",
       "\n",
       "   reactivity_0005  reactivity_0006  ...  reactivity_error_0197  \\\n",
       "0              NaN              NaN  ...                    NaN   \n",
       "1              NaN              NaN  ...                    NaN   \n",
       "2              NaN              NaN  ...                    NaN   \n",
       "3              NaN              NaN  ...                    NaN   \n",
       "4              NaN              NaN  ...                    NaN   \n",
       "\n",
       "   reactivity_error_0198  reactivity_error_0199  reactivity_error_0200  \\\n",
       "0                    NaN                    NaN                    NaN   \n",
       "1                    NaN                    NaN                    NaN   \n",
       "2                    NaN                    NaN                    NaN   \n",
       "3                    NaN                    NaN                    NaN   \n",
       "4                    NaN                    NaN                    NaN   \n",
       "\n",
       "   reactivity_error_0201  reactivity_error_0202  reactivity_error_0203  \\\n",
       "0                    NaN                    NaN                    NaN   \n",
       "1                    NaN                    NaN                    NaN   \n",
       "2                    NaN                    NaN                    NaN   \n",
       "3                    NaN                    NaN                    NaN   \n",
       "4                    NaN                    NaN                    NaN   \n",
       "\n",
       "   reactivity_error_0204  reactivity_error_0205  reactivity_error_0206  \n",
       "0                    NaN                    NaN                    NaN  \n",
       "1                    NaN                    NaN                    NaN  \n",
       "2                    NaN                    NaN                    NaN  \n",
       "3                    NaN                    NaN                    NaN  \n",
       "4                    NaN                    NaN                    NaN  \n",
       "\n",
       "[5 rows x 416 columns]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "train_data_pd = pd.read_csv(TRAIN_DATA_PATH)\n",
    "train_data_pd.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sequence</th>\n",
       "      <th>sequence_ext</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>GGGAACGACUCGAGUAGAGUCGAAAAAGAUCGCCACGCACUUACGA...</td>\n",
       "      <td>.....((((((.....)))))).....((((((((((((((....)...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>GGGAACGACUCGAGUAGAGUCGAAAAGGUGGCCGGCAGAAUCGCGA...</td>\n",
       "      <td>.....((((((.....))))))........(((((..(.....).....</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>GGGAACGACUCGAGUAGAGUCGAAAACAUUGUUAAUGCCUAUAUUA...</td>\n",
       "      <td>.....((((((.....))))))........(((((.((((.........</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>GGGAACGACUCGAGUAGAGUCGAAAAGGAGAUCGAAGACGACUUAC...</td>\n",
       "      <td>.....((((((.....))))))....((((((((.....(.........</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>GGGAACGACUCGAGUAGAGUCGAAAAGAUAUGGACUGACGAAGUCG...</td>\n",
       "      <td>.....((((((.....))))))....(((..(((((((((..((((...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                            sequence  \\\n",
       "0  GGGAACGACUCGAGUAGAGUCGAAAAAGAUCGCCACGCACUUACGA...   \n",
       "1  GGGAACGACUCGAGUAGAGUCGAAAAGGUGGCCGGCAGAAUCGCGA...   \n",
       "2  GGGAACGACUCGAGUAGAGUCGAAAACAUUGUUAAUGCCUAUAUUA...   \n",
       "3  GGGAACGACUCGAGUAGAGUCGAAAAGGAGAUCGAAGACGACUUAC...   \n",
       "4  GGGAACGACUCGAGUAGAGUCGAAAAGAUAUGGACUGACGAAGUCG...   \n",
       "\n",
       "                                        sequence_ext  \n",
       "0  .....((((((.....)))))).....((((((((((((((....)...  \n",
       "1  .....((((((.....))))))........(((((..(.....).....  \n",
       "2  .....((((((.....))))))........(((((.((((.........  \n",
       "3  .....((((((.....))))))....((((((((.....(.........  \n",
       "4  .....((((((.....))))))....(((..(((((((((..((((...  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_extracted_pd = pd.read_csv(TRAIN_DATA_EXT_PATH)\n",
    "train_extracted_pd.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(40000, 20000)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(train_data_pd), len(train_extracted_pd)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append('..')\n",
    "\n",
    "from python_scripts.transformers.dataset import RNADataset_train\n",
    "\n",
    "\n",
    "rna_dataset = RNADataset_train(\n",
    "    data=train_data_pd[:2000],\n",
    "    data_ext = train_extracted_pd[:1000],\n",
    "    vocab=pd.read_csv(VOCAB_PATH),\n",
    "    max_len=512\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1000"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(rna_dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.Size([512]), torch.Size([2, 512, 4]))"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rna_dataset[0][0].shape, rna_dataset[0][1].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "===========================================================================\n",
       "Layer (type:depth-idx)                             Param #\n",
       "===========================================================================\n",
       "BERTCustomRNAReactivity                            --\n",
       "├─BERTCustom: 1-1                                  --\n",
       "│    └─CombEmbedding: 2-1                          --\n",
       "│    │    └─TokenEmbedding: 3-1                    11,776\n",
       "│    │    └─PositionEmbedding: 3-2                 --\n",
       "│    │    └─Dropout: 3-3                           --\n",
       "│    └─ModuleList: 2-2                             --\n",
       "│    │    └─EncoderBlock: 3-4                      3,152,384\n",
       "│    │    └─EncoderBlock: 3-5                      3,152,384\n",
       "│    │    └─EncoderBlock: 3-6                      3,152,384\n",
       "│    │    └─EncoderBlock: 3-7                      3,152,384\n",
       "│    │    └─EncoderBlock: 3-8                      3,152,384\n",
       "│    │    └─EncoderBlock: 3-9                      3,152,384\n",
       "│    │    └─EncoderBlock: 3-10                     3,152,384\n",
       "│    │    └─EncoderBlock: 3-11                     3,152,384\n",
       "│    │    └─EncoderBlock: 3-12                     3,152,384\n",
       "│    │    └─EncoderBlock: 3-13                     3,152,384\n",
       "│    │    └─EncoderBlock: 3-14                     3,152,384\n",
       "│    │    └─EncoderBlock: 3-15                     3,152,384\n",
       "├─Linear: 1-2                                      4,104\n",
       "===========================================================================\n",
       "Total params: 37,844,488\n",
       "Trainable params: 37,844,488\n",
       "Non-trainable params: 0\n",
       "==========================================================================="
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from torchinfo import summary\n",
    "\n",
    "import sys\n",
    "sys.path.append('..')\n",
    "\n",
    "from python_scripts.transformers.model import BERTCustomRNAReactivity, BERTCustom\n",
    "from torch.utils.data import DataLoader\n",
    "\n",
    "bertmodel = BERTCustom(\n",
    "    vocab_size=len(rna_dataset.vocab),\n",
    "    hidden=512,\n",
    "    dim_k=64,\n",
    "    num_layer=12,\n",
    "    num_attn_head=8\n",
    ")\n",
    "RNA_model = BERTCustomRNAReactivity(bertmodel)\n",
    "\n",
    "summary(RNA_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([3, 2, 512, 4])"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "RNA_model(next(iter(DataLoader(rna_dataset, 3)))[0]).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "GPU available: True (mps), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n",
      "/Users/tglim/miniforge3/envs/autotrading/lib/python3.10/site-packages/lightning/pytorch/trainer/connectors/logger_connector/logger_connector.py:67: UserWarning: Starting from v1.9.0, `tensorboardX` has been removed as a dependency of the `lightning.pytorch` package, due to potential conflicts with other packages in the ML ecosystem. For this reason, `logger=True` will use `CSVLogger` as the default logger, unless the `tensorboard` or `tensorboardX` packages are found. Please `pip install lightning[extra]` or one of them to enable TensorBoard support by default\n",
      "  warning_cache.warn(\n",
      "\n",
      "  | Name  | Type                    | Params\n",
      "--------------------------------------------------\n",
      "0 | model | BERTCustomRNAReactivity | 37.8 M\n",
      "--------------------------------------------------\n",
      "37.8 M    Trainable params\n",
      "0         Non-trainable params\n",
      "37.8 M    Total params\n",
      "151.378   Total estimated model params size (MB)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sanity Checking: 0it [00:00, ?it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/tglim/miniforge3/envs/autotrading/lib/python3.10/site-packages/lightning/pytorch/trainer/connectors/data_connector.py:430: PossibleUserWarning: The dataloader, val_dataloader, does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` (try 10 which is the number of cpus on this machine) in the `DataLoader` init to improve performance.\n",
      "  rank_zero_warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sanity Checking DataLoader 0:   0%|          | 0/2 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/tglim/miniforge3/envs/autotrading/lib/python3.10/site-packages/lightning/pytorch/trainer/connectors/data_connector.py:370: UserWarning: You have overridden `on_before_batch_transfer` in `LightningModule` but have passed in a `LightningDataModule`. It will use the implementation from `LightningModule` instance.\n",
      "  warning_cache.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                                                           "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/tglim/miniforge3/envs/autotrading/lib/python3.10/site-packages/lightning/pytorch/trainer/connectors/data_connector.py:430: PossibleUserWarning: The dataloader, train_dataloader, does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` (try 10 which is the number of cpus on this machine) in the `DataLoader` init to improve performance.\n",
      "  rank_zero_warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0:   0%|          | 0/100 [00:00<?, ?it/s] "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/tglim/miniforge3/envs/autotrading/lib/python3.10/site-packages/torch/autograd/__init__.py:200: UserWarning: The operator 'aten::sgn.out' is not currently supported on the MPS backend and will fall back to run on the CPU. This may have performance implications. (Triggered internally at /Users/runner/work/pytorch/pytorch/pytorch/aten/src/ATen/mps/MPSFallback.mm:11.)\n",
      "  Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0: 100%|██████████| 100/100 [01:09<00:00,  1.44it/s, v_num=19, train_loss=0.362]\n",
      "Epoch 0, Avg. Training Loss: 0.4539 Avg. Validation Loss: 0.3347\n",
      "9.999969538319414e-05\n",
      "Epoch 1: 100%|██████████| 100/100 [01:08<00:00,  1.46it/s, v_num=19, train_loss=0.321, val_loss=0.312]\n",
      "Epoch 1, Avg. Training Loss: 0.3512 Avg. Validation Loss: 0.3018\n",
      "9.692465421332666e-05\n",
      "Epoch 2: 100%|██████████| 100/100 [01:09<00:00,  1.44it/s, v_num=19, train_loss=0.358, val_loss=0.302]\n",
      "Epoch 2, Avg. Training Loss: 0.3304 Avg. Validation Loss: 0.2995\n",
      "8.818981324193068e-05\n",
      "Epoch 3: 100%|██████████| 100/100 [01:10<00:00,  1.43it/s, v_num=19, train_loss=0.350, val_loss=0.299]\n",
      "Epoch 3, Avg. Training Loss: 0.3183 Avg. Validation Loss: 0.3014\n",
      "7.484872320267972e-05\n",
      "Epoch 4: 100%|██████████| 100/100 [01:09<00:00,  1.43it/s, v_num=19, train_loss=0.321, val_loss=0.301]\n",
      "Epoch 4, Avg. Training Loss: 0.3123 Avg. Validation Loss: 0.2966\n",
      "5.851051644782668e-05\n",
      "Epoch 5: 100%|██████████| 100/100 [01:09<00:00,  1.44it/s, v_num=19, train_loss=0.295, val_loss=0.296]\n",
      "Epoch 5, Avg. Training Loss: 0.3086 Avg. Validation Loss: 0.2977\n",
      "4.114582183825786e-05\n",
      "Epoch 6: 100%|██████████| 100/100 [01:08<00:00,  1.45it/s, v_num=19, train_loss=0.266, val_loss=0.297]\n",
      "Epoch 6, Avg. Training Loss: 0.3058 Avg. Validation Loss: 0.2948\n",
      "2.4849077819485582e-05\n",
      "Epoch 7: 100%|██████████| 100/100 [01:09<00:00,  1.44it/s, v_num=19, train_loss=0.290, val_loss=0.294]\n",
      "Epoch 7, Avg. Training Loss: 0.3047 Avg. Validation Loss: 0.2945\n",
      "1.1585912234500024e-05\n",
      "Epoch 8: 100%|██████████| 100/100 [01:09<00:00,  1.43it/s, v_num=19, train_loss=0.319, val_loss=0.294]\n",
      "Epoch 8, Avg. Training Loss: 0.3037 Avg. Validation Loss: 0.2942\n",
      "2.956058596327175e-06\n",
      "Epoch 9: 100%|██████████| 100/100 [01:08<00:00,  1.46it/s, v_num=19, train_loss=0.341, val_loss=0.294]\n",
      "Epoch 9, Avg. Training Loss: 0.3031 Avg. Validation Loss: 0.2944\n",
      "4.0461680586324365e-10\n",
      "Epoch 9: 100%|██████████| 100/100 [01:11<00:00,  1.40it/s, v_num=19, train_loss=0.341, val_loss=0.294]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=10` reached.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 9: 100%|██████████| 100/100 [01:11<00:00,  1.39it/s, v_num=19, train_loss=0.341, val_loss=0.294]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/tglim/miniforge3/envs/autotrading/lib/python3.10/site-packages/lightning/pytorch/trainer/connectors/data_connector.py:430: PossibleUserWarning: The dataloader, test_dataloader, does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` (try 10 which is the number of cpus on this machine) in the `DataLoader` init to improve performance.\n",
      "  rank_zero_warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Testing DataLoader 0: 100%|██████████| 13/13 [00:02<00:00,  5.80it/s]\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\">        Test metric        </span>┃<span style=\"font-weight: bold\">       DataLoader 0        </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━┩\n",
       "│<span style=\"color: #008080; text-decoration-color: #008080\">         test_loss         </span>│<span style=\"color: #800080; text-decoration-color: #800080\">    0.3092241585254669     </span>│\n",
       "└───────────────────────────┴───────────────────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1m       Test metric       \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m      DataLoader 0       \u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━┩\n",
       "│\u001b[36m \u001b[0m\u001b[36m        test_loss        \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m   0.3092241585254669    \u001b[0m\u001b[35m \u001b[0m│\n",
       "└───────────────────────────┴───────────────────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "[{'test_loss': 0.3092241585254669}]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torch\n",
    "import lightning.pytorch as pl\n",
    "from lightning.pytorch.callbacks import ModelCheckpoint, EarlyStopping\n",
    "\n",
    "import sys\n",
    "sys.path.append('..')\n",
    "\n",
    "from python_scripts.transformers.dataset import RNADataModule\n",
    "from python_scripts.transformers.task import RNATask\n",
    "\n",
    "rna_datamodule = RNADataModule(whole_train_dataset=rna_dataset, batch_size=8)\n",
    "\n",
    "def rna_rmse_loss(x: torch.tensor, y: torch.tensor, ignore_index=-100):\n",
    "    not_ignore = y != ignore_index\n",
    "    return torch.sqrt(torch.square(x[not_ignore] - y[not_ignore]).mean())\n",
    "\n",
    "def rna_mse_loss(x: torch.tensor, y: torch.tensor, ignore_index=-100):\n",
    "    not_ignore = y != ignore_index\n",
    "    return torch.square(x[not_ignore] - y[not_ignore]).mean()\n",
    "\n",
    "def rna_mae_loss(x: torch.tensor, y: torch.tensor, ignore_index=-100):\n",
    "    not_ignore = y != ignore_index\n",
    "    return torch.abs(x[not_ignore] - y[not_ignore]).mean()\n",
    "\n",
    "rna_optimizer = torch.optim.Adam(RNA_model.parameters(), 1e-3)\n",
    "# rna_optimizer = torch.optim.SGD(RNA_model.parameters(), 1e-3, 0.9)\n",
    "# rna_scheduler = torch.optim.lr_scheduler.CosineAnnealingLR(\n",
    "#     rna_optimizer,\n",
    "#     T_max=5,\n",
    "#     eta_min=1e-4,\n",
    "#     verbose=True,\n",
    "# )\n",
    "# rna_scheduler = torch.optim.lr_scheduler.MultiStepLR(\n",
    "#     rna_optimizer,\n",
    "#     [4, 7, 10, 13, 16, 19],\n",
    "#     verbose=True,\n",
    "#     gamma=0.3\n",
    "# )\n",
    "# rna_scheduler = torch.optim.lr_scheduler.CyclicLR(\n",
    "#     optimizer=rna_optimizer,\n",
    "#     base_lr=1e-6,\n",
    "#     max_lr=1e-3,\n",
    "#     step_size_up=3000,\n",
    "#     step_size_down=7000,\n",
    "#     verbose=True\n",
    "# )\n",
    "rna_scheduler = torch.optim.lr_scheduler.OneCycleLR(\n",
    "    optimizer=rna_optimizer,\n",
    "    max_lr=1e-4,\n",
    "    steps_per_epoch=100,\n",
    "    epochs=10,\n",
    "    div_factor=1e2,\n",
    "    pct_start=0.1,\n",
    "    verbose=False\n",
    ")\n",
    "\n",
    "rna_task = RNATask(\n",
    "    model=RNA_model,\n",
    "    loss_fn=rna_mae_loss,\n",
    "    optimizer=rna_optimizer,\n",
    "    scheduler=rna_scheduler,\n",
    ")\n",
    "\n",
    "callbacks = []\n",
    "callbacks.append(ModelCheckpoint(\n",
    "    monitor='val_avg_loss',\n",
    "    save_top_k=3,\n",
    "    mode='min'\n",
    "))\n",
    "# callbacks.append(EarlyStopping(\n",
    "#     monitor='val_avg_loss',\n",
    "#     min_delta=0.001,\n",
    "#     patience=3,\n",
    "#     verbose=True,\n",
    "#     mode='min'\n",
    "# ))\n",
    "\n",
    "trainer = pl.Trainer(\n",
    "    max_epochs=10,\n",
    "    callbacks=callbacks,\n",
    ")\n",
    "\n",
    "# rna_task = RNATask.load_from_checkpoint(\n",
    "#     checkpoint_path='./lightning_log/~~'\n",
    "#     model=RNA_model,\n",
    "#     loss_fn=rna_mae_loss,\n",
    "#     optimizer=rna_optimizer,\n",
    "#     scheduler=rna_scheduler,\n",
    "# )\n",
    "\n",
    "# trainer.fit(rna_task, ckpt_path=\"some/path/to/my_checkpoint.ckpt\")# trainer = pl.Trainer(resume_from_checkpoint='../notebooks/lightning_logs/version_0/checkpoints/epoch=0-step=100.ckpt')\n",
    "\n",
    "trainer.fit(rna_task, datamodule=rna_datamodule)\n",
    "trainer.test(rna_task, datamodule=rna_datamodule)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "autotrading",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
